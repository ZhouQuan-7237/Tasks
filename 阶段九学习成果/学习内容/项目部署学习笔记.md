# 项目部署学习笔记——周全

## 学习目录

一.nginx学习

1.基础介绍

2.主要特点

3.常用命令

二.正反代理

1.正向代理

2.反向代理

3.两者异同

三.负载均衡

1.简单介绍

2.常见算法

四.服务部署

1.简单介绍

2.操作步骤

## 学习内容

### 一.nginx学习

#### 1.基础介绍

Nginx是一个轻量级、高性能的 Web 服务器、反向代理服务器和及电子邮件代理服务器，广泛应用于高并发、高负载的互联网项目。

#### 2.主要特点

**(1) 高性能**：支持高达50,000个并发连接，适用于大流量网站。

**(2) 低内存消耗**：占用内存少，启动速度快，适合处理大量请求。

**(3) 反向代理与负载均衡**：提供反向代理、负载均衡功能，常与其他后端服务（如Tomcat、PHP）结合使用。

**(4) 支持多协议**：支持HTTP、HTTPS、SMTP、POP3和IMAP协议。

**(5) 稳定性高**：支持热部署，能够长时间运行而不需要重启。

#### 3.常用命令

* **nginx -s stop**：快速关闭 Nginx 服务，可能不保存相关数据，立即终止 Web 服务。

* **nginx -s quit**：平稳关闭 Nginx，保存相关数据，正常结束 Web 服务。

* **nginx -s reload**：重新加载 Nginx 配置文件，使更改生效。

* **nginx -s reopen**：重新打开 Nginx 日志文件，常用于日志轮换。

* **nginx -c filename**：指定自定义配置文件，替代默认配置文件。

* **nginx -t**：测试配置文件的语法是否正确，并检查配置文件中引用的文件是否存在，但不启动 Nginx 服务。

* **nginx -v**：显示 Nginx 的版本。

* **nginx -V**：显示 Nginx 的版本、编译器版本及编译时的配置参数。

### 二.反向代理

#### 1.正向代理

![image-20250214150738087](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/image-20250214150738087.png)

**(1) 定义**：正向代理是位于客户端与目标服务器之间的代理服务器。客户端通过正向代理访问互联网，代理服务器转发客户端请求并获取目标服务器的响应后返回给客户端。

**(2) 特点** ：

- 客户端需要主动设置代理服务器，才能使用正向代理。
- 代理服务器可以突破访问限制，访问原本无法直接访问的内容。

**(3) 实例**：在中国访问谷歌，客户端通过 VPN 或代理服务器访问被封锁的外部网站。

#### 2.反向代理

![image-20250214150805262](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/image-20250214150805262.png)

**(1) 定义**：反向代理是位于客户端和目标服务器之间的代理服务器。代理服务器来接收客户端的请求，然后将请求转发给内部网络上的服务器，将从服务器上得到的结果返回给客户端。客户端对代理服务器是透明的，它只知道代理服务器的地址，不直接接触到真实的目标服务器。

**(2) 特点** ：

- 客户端不需要任何特殊设置，直接将请求发送给反向代理服务器。
- 反向代理服务器可以对客户端隐藏后端服务器的真实IP地址。

**(3) 实例**：在访问淘宝、京东等大型网站时，反向代理帮助分担服务器的负载，并隐藏内部服务器的具体信息。

#### 3.两者异同

**(1) 相同点**：两者都充当了客户端与服务器之间的中介角色，都会转发客户端的请求，并将响应返回给客户端。

**(2) 不同点**：

- 正向代理是**客户端的代理**，目标服务器不知道客户端的真实信息。
- 反向代理是**服务器端的代理**，客户端对代理服务器透明，目标服务器对外只暴露代理服务器的地址，隐藏了实际的服务器 IP。

### 三.负载均衡

#### 1.简单介绍

负载均衡是一种技术，通过将客户端的请求分发到多个服务器上，避免单台服务器因过高的请求量而崩溃或性能下降。它通常应用于服务器集群中，确保请求的均匀分配，从而提升系统的可用性、扩展性，并保障高并发环境下的稳定性。

![image-20250223194539340](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/image-20250223194539340.png)

#### 2.常见算法

##### 2.1 轮询

![202310250648178](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/202310250648178.png)

**（1）介绍**

轮询算法是一种将客户端请求按顺序轮流分配到多个服务器的负载均衡策略。

**（2）原理**

当接收到请求时，负载均衡器按照服务器列表的顺序逐个将请求转发到后端服务器。每个服务器轮流接收请求，直到所有服务器被轮询一遍，然后重新开始。



如上图所示，负载均衡器收到来自客户端的 6 个请求，编号为1到6。

负载均衡器按照固定的顺序（0 → 1 → 2 → 0 → 1 → 2）依次将请求分配给服务器。

请求1：分配给服务端0        请求2：分配给服务端1 请求3：分配给服务端2

请求4：再次轮回到服务端0 请求5：分配给服务端1 请求6：分配给服务端2。

**（3）优点**

* **实现简单**：易于理解和实现。

- **无状态**：不需要记录请求状态，服务器之间相互独立。

**（4）缺点**

- **不考虑负载**：不考虑服务器的实际负载情况，可能导致性能较差的服务器过载。

##### 2.2 加权轮询

![202310250649943](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/202310250649943.png)

**（1）介绍**

加权轮询算法是对传统轮询算法的改进，通过为每台服务器分配权重值，优先将请求分配给处理能力更强、资源配置更高的服务器。

**（2）原理**
每台后端服务器根据其处理能力或资源配置分配一个权重值。负载均衡器在接收到请求时，根据这些权重值依次将请求分配给不同的服务器。权重较大的服务器将接收更多的请求，而权重较小的服务器接收较少的请求。



如上图所示，三个服务器1、2、3的权重值分别为3、1和2。

负载均衡器收到来自客户端的 6 个请求，编号为1到6。

负载均衡器按照权重大小顺序依次将请求分配给服务器。

请求1：分配给服务器0（权重3） 请求2：分配给服务器0（权重3） 请求3：分配给服务器0（权重3）

请求4：分配给服务器1（权重1） 请求5：分配给服务器2（权重2） 请求6：分配给服务器2（权重2）。

**（3）优点**

* **弹性调度**：根据服务器的性能或资源配置，灵活地分配请求，使得资源得到更有效的利用。
* **均衡性较好**：相比于简单的轮询算法，加权轮询算法更加均衡，能够更好地适应不同服务器的性能差异。

**（4）缺点**

- **配置复杂**：需要事先对每个服务器的权重进行合理设置，配置过程相对复杂。
- **无法动态调整**：权重值一旦设置完成，无法动态调整，可能无法应对服务器负载变化的情况。

##### 2.3 最少连接![202310250650852](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/202310250650852.png)

（1）介绍

最小连接数算法根据后端服务器当前的连接数来动态分配请求，将新的请求分配给连接数最少的服务器，从而实现负载均衡。

（2）原理

- 负载均衡器实时监控每台服务器的连接数。
- 请求会被分配给连接数最少的服务器，以确保负载均衡。
- 若多台服务器连接数相同，则可以进一步根据其他因素（如权重）做出决策。



如上图所示，两个服务器0、1的处理能力相同，

负载均衡器收到来自客户端的 6 个请求，编号为1到6。

* **初始状态**：

  - 服务端 0：连接数为 0

  - 服务端 1：连接数为 0

* **请求 1 到达**：

  - 服务端 0 连接数最少，分配给服务端 0。

  - 服务端 0：连接数为 1

  - 服务端 1：连接数为 0

* **请求 2 到达**：

  - 服务端 1 连接数最少，分配给服务端 1。

  - 服务端 0：连接数为 1

  - 服务端 1：连接数为 1

* **请求 3 到达**：

  - 服务端 0 连接数最少，分配给服务端 0。

  - 服务端 0：连接数为 2

  - 服务端 1：连接数为 1

* **请求 4 到达**：

  - 服务端 1 连接数最少，分配给服务端 1。

  - 服务端 0：连接数为 2

  - 服务端 1：连接数为 2

* **请求 5 到达**：

  - 服务端 0 和服务端 1 的连接数相同，假设选择服务端 0。

  - 服务端 0：连接数为 3

  - 服务端 1：连接数为 2

* **请求 6 到达**：

  - 服务端 1 连接数最少，分配给服务端 1。

  - 服务端 0：连接数为 3

  - 服务端 1：连接数为 3

**（3）优点**

- **动态负载均衡**：根据服务器当前的连接数动态调整请求分配，确保负载均衡。

**（4）缺点**

* **连接数不完全代表负载**：连接数和服务器负载并非总是正相关，某些服务器即使连接数多，处理能力可能也较强。

##### 2.4 加权最少连接

**（1）介绍**

加权最少连接数算法在最少连接数算法的基础上引入了服务器的权重概念。每台服务器根据其性能或资源配置分配一个权重值，并根据这个权重值计算该服务器能处理的连接数。请求优先被分配到当前连接数最少且能处理更多请求的服务器。

**（2）原理**

* 每台服务器根据性能（如 CPU、内存、负载能力等）分配一个权重。
* 负载均衡器会计算每台服务器的“加权连接数”，即连接数与服务器权重的比值。
* 请求会被分配给加权连接数最小的服务器，这样高性能服务器能够处理更多的请求，而低性能服务器负载较轻。

​	

* **加权最少连接数算法的步骤：**
  * 维护每台服务器的当前连接数和权重值。
  * 根据权重计算每台服务器能处理的连接数。
  * 将新请求分配给加权连接数最少的服务器。
  * 如果有多个服务器连接数相同，则根据权重进一步分配。

**（3）优点**

- **负载均衡效果好**：综合考虑服务器的连接数和权重，能够更精确地分配负载，避免服务器过载或空闲。

**（4）缺点**

- **算法复杂性高**：实现较为复杂，需要实时监控服务器的连接数并进行计算和选择。

##### 2.5 IP Hash

**（1）介绍**

IP Hash通过对客户端的IP地址进行哈希计算，将请求固定分配到同一台服务器上，从而保证来自相同IP地址的请求始终转发到相同的服务器。

**（2）原理**

IP Hash算法将客户端的IP地址通过哈希函数计算得到一个值，并将该哈希值对服务器数量进行取模运算，结果决定了请求分配到哪台服务器。由于同一个IP地址每次经过哈希计算得到的结果相同，因此同一IP的请求总是会被分配到同一台服务器，从而实现了会话粘滞。

**（3）优点**

* **会话保持**：IP Hash算法确保同一IP地址的请求始终被分配到同一台服务器，提高了应用程序的稳定性，确保了会话数据的一致性。

**（4）缺点**

* **不适用于动态环境**：当客户端IP发生变化时（如IP变动或重新分配），会导致请求被分配到不同的服务器，可能导致会话数据丢失或不一致。
* **不考虑服务器负载**：IP Hash算法不考虑服务器的当前负载情况，如果某台服务器负载过高，算法无法动态地将请求分配到负载较低的服务器上。

##### 2.6 普通 hash![202310250652913](https://raw.githubusercontent.com/ZhouQuan-7237/image-bed/main/202310250652913.png)

**（1）介绍**

哈希算法通过对客户端请求的某些信息（如IP地址、URL等）进行哈希计算，将请求分配到特定的服务器上。该算法确保相同的请求总是被分配到同一台服务器，从而实现会话粘滞。

**（2）原理**

负载均衡器从客户端请求中提取特定信息（如IP地址、URL等）并对提取的信息进行哈希计算，生成一个哈希值，然后将哈希值与服务器列表的大小进行取模运算，得到的结果即为选中的服务器序号，最后将请求发送到所映射的服务器上进行处理。

**（3）优点**

* **会话粘滞**：对于需要会话保持的场景，哈希算法可以确保同一客户端请求始终访问同一台服务器。

**（4）缺点**

* **扩展性差**：当服务器列表发生变化时，需要重新计算哈希值并重新映射，影响系统的扩展性和可用性。
* **数据迁移成本高**：在增减节点时，由于哈希取模函数的基数变化，会导致大量数据的迁移，增加系统的复杂性和成本。

### 四.服务部署

#### 1.简单介绍

在 Nginx 上部署多个不同的服务通常是指将多个服务绑定到不同的域名、路径或端口上。

每个服务可以是独立的 Web 应用或 API，可能运行在不同的端口或服务器上。

#### 2.操作步骤

假设有以下两个服务：

- **服务 1**：一个静态网站，运行在 `http://localhost:8081`
- **服务 2**：一个后端 API，运行在 `http://localhost:8082`

我希望通过Nginx将不同的域名或路径请求代理到这些服务

有以下两种方式：

#### （1）不同域名部署多个服务

比如我希望通过两个不同的域名访问不同的服务：

- `www.site1.com` -> 服务 1（静态网站）
- `www.site2.com` -> 服务 2（API）

我可以在Nginx配置中配置两个不同的 `server` 块来实现这一目标。



##### step 1.编辑 Nginx 配置文件

打开 Nginx 的默认配置文件 `/etc/nginx/sites-available/default` 或者创建新配置文件。

```bash
sudo nano /etc/nginx/sites-available/site1_and_site2.conf
```

##### step 2.配置多个服务

```nginx
server {
    listen 80;
    server_name www.site1.com;

    location / {
        root /var/www/site1;  # 静态网站目录
        index index.html index.htm;
    }
}

server {
    listen 80;
    server_name www.site2.com;

    location / {
        proxy_pass http://localhost:8082;  # 后端服务，假设在 8082 端口运行
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

这个配置将：

- 对于 `www.site1.com` 的请求，返回存放在 `/var/www/site1` 目录下的静态网站。
- 对于 `www.site2.com` 的请求，转发到 `http://localhost:8082`，即后端的 API 服务。

##### step 3.配置符号链接

创建符号链接到 `sites-enabled` 目录，以便启用配置文件。

```bash
sudo ln -s /etc/nginx/sites-available/site1_and_site2.conf /etc/nginx/sites-enabled/
```

##### step 4.测试 Nginx 配置

运行以下命令来检查Nginx配置是否正确：

```bash
sudo nginx -t
```

##### step 5.重新加载 Nginx

重新加载Nginx，使配置生效：

```bash
sudo systemctl reload nginx
```

##### step 6.配置 DNS 或 `/etc/hosts` 文件

如果使用域名访问这些服务，需要将域名指向Nginx服务器的 IP 地址。

在生产环境中，这些设置通常通过 DNS 来完成。

在测试环境中，可以通过编辑 `/etc/hosts` 文件，将域名指向本地 IP：

```bash
sudo nano /etc/hosts
```

添加如下内容：

```bash
127.0.0.1   www.site1.com
127.0.0.1   www.site2.com
```

##### step 7.配置防火墙

确保允许 HTTP 流量通过：

```bash
sudo ufw allow 'Nginx Full'
```

##### step 8.测试

浏览器中访问：

- `http://www.site1.com`，它将加载静态网站服务
- `http://www.site2.com`，它将代理到后端 API 服务

#### （2）同一域名部署多个服务

比如我希望通过同一个域名，但不同路径来部署多个服务：

- `www.site.com/service1` -> 服务 1
- `www.site.com/service2` -> 服务 2

我可以使用路由代理，比如可以这样配置：

```nginx
server {
    listen 80;
    server_name www.site.com;

    location /service1 {
        proxy_pass http://localhost:8081;  # 服务 1
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /service2 {
        proxy_pass http://localhost:8082;  # 服务 2
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

这样，当我访问：

- `www.site.com/service1` 时，将访问服务 1
- `www.site.com/service2` 时，将访问服务 2

## 参考资料

请查阅阶段九任务计划思路